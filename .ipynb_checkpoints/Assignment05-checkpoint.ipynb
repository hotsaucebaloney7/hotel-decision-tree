{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Python for Data Science\n",
    "\n",
    "## Assignment 5 - Machine Learning\n",
    "\n",
    "In this assignment you will use Pandas to prepare a dataset for machine learning classificaiton.   You will then build a decision tree model, separating the data into training and validation sets, and calculate the accuracy of the model.\n",
    "\n",
    "Some helpful Resources:\n",
    "\n",
    "- [Pandas Website](https://pandas.pydata.org/)\n",
    "- [Kaggle Hotel Booking Cancellation Dataset](https://www.kaggle.com/vinayakashastri/hotel-booking-cancellation-dataset?select=hotel_bookings.csv)\n",
    "\n",
    "## Tasks\n",
    "\n",
    "1. Download and load `hotel_bookings.csv` from Kaggle\n",
    "2. Use Pandas to explore and preprocess the data.   Idenitfy columns which need preprocessing (conversion of categorial data to numeric vaules, fill empty values, drop columns which are not likely to help with classification)\n",
    "3. Split the data into training and validation datsets\n",
    "4. Train a Decision Tree classifier using the training data\n",
    "5. Predict classifications for the validation data\n",
    "6. Score the model's accuracy\n",
    "\n",
    "While not required, extra credit will be available to those who work to tune their model to improve it's accuracy.\n",
    "\n",
    "As you build out this notebook create lots of cells -- small snippets of code followed or prefaced by comments in \"markdown\" cells.   A complete solution will be well structured and well documented.\n",
    "\n",
    "## Rubric\n",
    "\n",
    "The rubric for this assignment:\n",
    "\n",
    "- 40 Methodical approahc to preprocessing data is evident\n",
    "- 30 Decision tree successfully trained and validated\n",
    "- 20 Appoach is well structured\n",
    "- 10 Notebook is well documented\n",
    "- 10 Extra credit points for models which achieve validation accuracy above 85%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our typical libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Data\n",
    "\n",
    "`hotel_bookings.csv` contains 119390 records representing individual reservations at a collection of hotels.  Each record is classified to show if the reservation was cancelled or not.   Your challenge is to create a machine learning model which can accurately predict whether or not a reservation will be cancelled based on the available data.\n",
    "\n",
    "One wrinkle in the data: there are two columns which represent whether or not a reservation was cancelled.   They are **'is_cancelled'** and **'reservation_status'** -- and if you feed one of them as an attribute then the model will easily achieve 100% accuracy.   So to properly create the model you should drop one, and I recommend dropping **'reservation_status'**.\n",
    "\n",
    "\n",
    "## 1.  Dowload and load hotel_bookings.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('hotel_bookings.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Use Pandas to explore and preprocess the data\n",
    "\n",
    "\n",
    "### Deal with Null Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we remove a few attributes that either have too many null values or don't provide a substantial benefit to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removed as it gives similar information to 'is_cancelled'.\n",
    "df.drop('reservation_status', axis=1, inplace=True) \n",
    "#Very few company entries were filled so we're dropping it.\n",
    "df.drop('company', axis=1, inplace=True)   \n",
    "#There are enough agents missing where we are going to drop it. The number is more or less categorical so using a median or average does not make sense. I feel it is too many values to fill randomly.\n",
    "df.drop('agent', axis=1, inplace=True)     \n",
    "#I am afraid of this information not being helpful as it only gives the latest date for a status change for placing the reservation or canceling it. I am a little concerned with this causing issues for overfitting.\n",
    "df.drop('reservation_status_date', axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will fill the NaN values in the country attribute with the most common value. The magnitude of the numbers will hopefully make it fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['country'] = df['country'].fillna('PRT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are only 4 observations with null values for children we're going to fill them randomly based on what options were picked by other observations (0 to 2 since they are by far the most prominent). 4 observations shouldn't hurt things too much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0     110798\n",
       "1.0       4861\n",
       "2.0       3654\n",
       "3.0         76\n",
       "10.0         1\n",
       "Name: children, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['children'] = df['children'].fillna(-1)\n",
    "np.random.seed(123456)                    \n",
    "df.loc[df['children'] == -1,'children'] = df['children'].apply(lambda x: np.random.randint(0,3))\n",
    "df['children'].value_counts()              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null values are dealt with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hotel                             0\n",
       "is_canceled                       0\n",
       "lead_time                         0\n",
       "arrival_date_year                 0\n",
       "arrival_date_month                0\n",
       "arrival_date_week_number          0\n",
       "arrival_date_day_of_month         0\n",
       "stays_in_weekend_nights           0\n",
       "stays_in_week_nights              0\n",
       "adults                            0\n",
       "children                          0\n",
       "babies                            0\n",
       "meal                              0\n",
       "country                           0\n",
       "market_segment                    0\n",
       "distribution_channel              0\n",
       "is_repeated_guest                 0\n",
       "previous_cancellations            0\n",
       "previous_bookings_not_canceled    0\n",
       "reserved_room_type                0\n",
       "assigned_room_type                0\n",
       "booking_changes                   0\n",
       "deposit_type                      0\n",
       "days_in_waiting_list              0\n",
       "customer_type                     0\n",
       "adr                               0\n",
       "required_car_parking_spaces       0\n",
       "total_of_special_requests         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert non-numeric (categorical) data to numeric values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of these are fairly straightforward reassignments from string to numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['arrival_date_month']=df['arrival_date_month'].map({'January': 1, 'February':2, 'March':3, 'April':4, 'May':5, 'June':6, \n",
    "                                                       'July':7, 'August':8, 'September':9, 'October':10, 'November':11, \n",
    "                                                       'December':12})\n",
    "df['hotel'] = df['hotel'].map({'City Hotel': 0, 'Resort Hotel': 1})\n",
    "df['assigned_room_type'] = df['assigned_room_type'].map({'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, \n",
    "                                                         'I': 9, 'K': 11, 'L': 12, 'P': 16})\n",
    "df['deposit_type'] = df['deposit_type'].map({'No Deposit': 0, 'Non Refund': 1, 'Refundable': 2})\n",
    "df['customer_type'] = df['customer_type'].map({'Transient': 0, 'Transient-Party': 1, 'Contract': 2, 'Group': 3})\n",
    "df['meal'] = df['meal'].map({'BB': 0, 'HB': 1, 'SC': 2, 'Undefined': 3, 'FB': 4})\n",
    "df['market_segment'] = df['market_segment'].map({'Online TA': 0, 'Offline TA/TO': 1, 'Groups': 2, 'Direct': 3, 'Corporate': 4, 'Complementary': 5, 'Aviation': 6, 'Undefined': 7})\n",
    "df['distribution_channel'] = df['distribution_channel'].map({'TA/TO': 0, 'Direct': 1, 'Corporate': 2, 'GDS': 3, 'Undefined': 4})\n",
    "df['reserved_room_type'] = df['reserved_room_type'].map({'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, \n",
    "                                                        'L': 12, 'P': 16})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were a lot of countries so I had to get creative mapping all of these. I do question the elegance of my code here because the for loop looks sloppy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_dict = {}\n",
    "for i in range(len(df.country.unique())):\n",
    "    country_dict[df.country.unique()[i]]=i\n",
    "df['country'] = df['country'].map(country_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split the data into training and validation datsets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the same code from the lecture, swapping out the variables used in class with mine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = df.drop('is_canceled', axis=1)\n",
    "y = df.is_canceled\n",
    "\n",
    "x_train,x_validate,y_train,y_validate=train_test_split(x,y,test_size=0.2,random_state=123456)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train a Decision Tree classifier using the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much like the last cell this was taken from the lecture. The seed was set to keep everything repeatable for checking work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=123456)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "HotelDT = DecisionTreeClassifier(random_state=123456)\n",
    "HotelDT.fit( x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Predict classifications for the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We send the prediction\n",
    "y_predict = HotelDT.predict(x_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Score the model's accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's funny that I am merely .33% off. I considered taking out less relevant attributes but I didn't see any I felt comfortable removing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy against training data is 99.62%\n",
      "Overall accuracy against validation data is 84.66%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.88     14973\n",
      "           1       0.79      0.81      0.80      8905\n",
      "\n",
      "    accuracy                           0.85     23878\n",
      "   macro avg       0.84      0.84      0.84     23878\n",
      "weighted avg       0.85      0.85      0.85     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "print(f'Overall accuracy against training data is {HotelDT.score(x_train, y_train):5.2%}')\n",
    "print(f'Overall accuracy against validation data is {HotelDT.score(x_validate, y_validate):5.2%}')\n",
    "print(classification_report(y_validate, y_predict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Extra Credit\n",
    "\n",
    "For those of you with an interestin machine learning, here's a chance to explore ways to tune a decisiontree model for improved performance.   You can use various strategies - limit the depth of the tree, require a minimum number of samples for a split.  You can even create a *Random Forest* - a collection of small decision trees which work together to classify data.   \n",
    "\n",
    "If you can crate a classifier with accuaracy above 85% you have done well -- and will be awarded 10 extra credit points for your effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
